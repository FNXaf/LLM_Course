{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPk6QIevCT5cVt5A5d6AAbp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FNXaf/LLM_Course/blob/main/day1_session3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnYhFoFnvhDC"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('gemini_api_key')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Bz9vFxDCzads",
        "outputId": "64a4e2c7-5d4f-4a01-dc8a-0f4406f62790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyAA4UK044NrWZrrmczUqnMvY1Ypy0V2JF0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "GEeQWqNFzcIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key= api_key)\n",
        "llm=genai.GenerativeModel('gemini-2.5-flash')\n",
        "response = llm.generate_content(\"Timro naam k ho? \")"
      ],
      "metadata": {
        "id": "QPteS7EBzj8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "EiruPLKp1URu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hlFyyLy1V7R",
        "outputId": "a0de97a0-0bc0-4486-c219-8b049c191cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mero naam chhaina. Ma Google dwara prashikshit ek bishal bhasha model hu.\n",
            "\n",
            "(I don't have a name. I am a large language model trained by Google.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tune the LLM model\n",
        "generation_config = {\n",
        "    'temperature':0.6,\n",
        "    'max_output_count': 8000,\n",
        "    'candidate count':1,\n",
        "}"
      ],
      "metadata": {
        "id": "XEUgazux4G-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = genai.GenerativeModel(\n",
        "    model_name = 'gemini-2.5-flash',\n",
        "    generation_config = generation_config,\n",
        "    system_instruction='You are the professor of Engineering college'\n",
        ")"
      ],
      "metadata": {
        "id": "5GUYclKK4n-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = 'What is theory of relativity'"
      ],
      "metadata": {
        "id": "znq5rENt5S-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start session\n",
        "chat_session = llm.start_chat()"
      ],
      "metadata": {
        "id": "voJ4EIuF5mnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response= chat_session.send_message(input)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "fOfoLxVn5x6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Framework to work with LLM models for orchestration\n",
        "- LANGCHAIN..\n",
        "- LAMAINDEX\n",
        "- HAYSTACK"
      ],
      "metadata": {
        "id": "IBhp72H06qgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#chatapi using langchain\n",
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "id": "m0jgKct66z0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "wjRc2PZR7I85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model= \"gemini-2.5-flash\", api_key=api_key)"
      ],
      "metadata": {
        "id": "mHmOmEgh7RjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result= llm.invoke(\"Tell me a joke in Nepali about realtionship\")\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "DQWnBHT37evJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let's playaround with Prompt template"
      ],
      "metadata": {
        "id": "NYo_Y-mJ9dua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_string= \"\"\" Translate the next \\\n",
        "that is delimied by triple backticks \\\n",
        "into a style that is {style}\n",
        "text: '''{text}'''\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tgo-EsCU7oAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "KQmIZzLk9xwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages[0].prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7by_PGUw9_pf",
        "outputId": "c7d72e3a-b0ae-4c05-e328-3e049c06e8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template=\" Translate the next that is delimied by triple backticks into a style that is {style}\\ntext: '''{text}'''\\n\")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_style = \"\"\" pure nepali \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RuKtYMd1-ZYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\" Welcome to GenAI Tutorial \\\n",
        "class. This is day1 . We are using Google geimini flash moel\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nyix12IQ-kpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_style = \"\"\"a polite tone \\ that speaks in german\"\"\"\n",
        "service_reply= \"\"\"Hey Customer, the warrenty doesnt cover cleaning \\\n",
        "expense for your kitchen items. \"\"\""
      ],
      "metadata": {
        "id": "QK-PTyEUAr41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "customer_messages = prompt_template.format_messages(\n",
        "    style = service_style,\n",
        "    text= service_reply\n",
        ")"
      ],
      "metadata": {
        "id": "JkCqShqp-0do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(customer_messages[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VovEyWfS_FmS",
        "outputId": "3dd3ac42-1623-4d90-dd8f-9c63db34e753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\" Translate the next that is delimied by triple backticks into a style that is a polite tone \\\\ that speaks in german\\ntext: '''Hey Customer, the warrenty doesnt cover cleaning expense for your kitchen items. '''\\n\" additional_kwargs={} response_metadata={}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets call LLM Model to translate the style of the customer messages\n",
        "customer_response = llm.invoke(customer_messages)\n",
        "print(customer_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2myZtr-_Ij5",
        "outputId": "ed3a31b7-0410-4757-85a4-d866cda62989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Sehr geehrte Kundin, sehr geehrter Kunde,\\n\\nBitte beachten Sie, dass die Garantie leider keine Kosten für die Reinigung Ihrer Küchenartikel abdeckt.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--b0bd2d51-b048-4aad-90d1-3ba55fa57ed9-0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdNHIncF_imn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}